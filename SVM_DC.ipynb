{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vx1E1DqZWtwc",
    "outputId": "b1c47dff-dc7d-4ebf-a6e6-0383903ade5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpQlQGFdX3RL",
    "outputId": "7b6a074a-7ce4-461c-e499-1f8e5dfa9f14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MXn7eOEVzy5",
    "outputId": "e84c8044-7861-4028-8e08-26fb6430be55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Category\n",
      "0  Lufthansa flies back to profit.German airline ...  business\n",
      "1  Japanese growth grinds to a halt\\n\\nGrowth in ...  business\n",
      "2  WorldCom director admits lying\\n\\nThe former c...  business\n",
      "3  Glaxo aims high after profit fall\\n\\nGlaxoSmit...  business\n",
      "4  Peugeot deal boosts Mitsubishi\\n\\nStruggling J...  business\n",
      "Number of Total Documents Before: 999\n",
      "Number of Duplicates Before: 19\n",
      "Number of Total Documents After: 980\n",
      "Number of Duplicates After: 0\n",
      "Accuracy: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       1.00      0.95      0.97        20\n",
      "           3       0.96      1.00      0.98        26\n",
      "           4       1.00      1.00      1.00        12\n",
      "           5       0.92      1.00      0.96        23\n",
      "           6       1.00      1.00      1.00        20\n",
      "           7       1.00      1.00      1.00        20\n",
      "           8       0.88      1.00      0.93        21\n",
      "           9       0.94      0.77      0.85        22\n",
      "\n",
      "    accuracy                           0.96       196\n",
      "   macro avg       0.97      0.97      0.97       196\n",
      "weighted avg       0.97      0.96      0.96       196\n",
      "\n",
      "\n",
      "Number of documents in each content category:\n",
      "graphics         100\n",
      "space            100\n",
      "business          99\n",
      "technologie       99\n",
      "food              98\n",
      "politics          98\n",
      "entertainment     97\n",
      "historical        97\n",
      "medical           96\n",
      "sport             96\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "\n",
    "# Load the Excel data\n",
    "file_path = '/content/drive/MyDrive/SLT/Preprocessed data.xlsx'  # Replace with your file path\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head())\n",
    "content_to_label = {\n",
    "    'sport': 0,\n",
    "    'technologie': 1,\n",
    "    'business': 2,\n",
    "    'graphics': 3,\n",
    "    'entertainment': 4,\n",
    "    'politics': 5,\n",
    "    'food': 6,\n",
    "    'historical': 7,\n",
    "    'medical': 8,\n",
    "    'space': 9\n",
    "}\n",
    "\n",
    "# Convert content categories to numerical labels\n",
    "data['label'] = data['Category'].map(content_to_label)\n",
    "\n",
    "# Handling missing values in the label column\n",
    "data.dropna(subset=['label'], inplace=True)\n",
    "\n",
    "# Define lemmatizer and stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabetic characters and lowercase\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", str(text)).lower()\n",
    "\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stop words, lemmatize, and stem\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words if word not in stop_words]\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing to the 'Text' column\n",
    "data['Processed_Text'] = data['Text'].apply(preprocess_text)\n",
    "\n",
    "# Print the number of total documents before dropping\n",
    "total_docs_before = len(data)\n",
    "print(f\"Number of Total Documents Before: {total_docs_before}\")\n",
    "\n",
    "# Print the number of duplicates before dropping\n",
    "num_duplicates_before = data.duplicated(subset='Processed_Text').sum()\n",
    "print(f\"Number of Duplicates Before: {num_duplicates_before}\")\n",
    "\n",
    "# Drop duplicates based on the 'Processed_Text' column\n",
    "data = data.drop_duplicates(subset='Processed_Text', keep='first')\n",
    "\n",
    "# Print the number of total documents after dropping\n",
    "total_docs_after = len(data)\n",
    "print(f\"Number of Total Documents After: {total_docs_after}\")\n",
    "\n",
    "# Print the number of duplicates after dropping\n",
    "num_duplicates_after = data.duplicated(subset='Processed_Text').sum()\n",
    "print(f\"Number of Duplicates After: {num_duplicates_after}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Processed_Text'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')  # You can experiment with different kernels (linear, rbf, etc.)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Find the number of documents in each content category\n",
    "content_counts = data['Category'].value_counts()\n",
    "print(\"\\nNumber of documents in each content category:\")\n",
    "print(content_counts)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
